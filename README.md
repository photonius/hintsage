Адаптеры для сервиса помощи в прохождении собеседований https://hintsage.com

# LLM Адаптеры - директория llm

Здесь находятся адаптеры сервисов, предоставляющих LLM-модели для генерации текста на основе запроса.

- `openai_server.py` — адаптер для OpenAI сервера: https://openai.com/api/
- `openrouter_server.py` — адаптер для OpenRouter сервера: https://openrouter.ai/

---

## Интерфейс API

Каждый адаптер реализует два эндпоинта с одинаковыми структурами запросов и ответов.

### POST `/answer/stream`

**Описание:** Генерирует текстовый ответ на запрос пользователя с поддержкой истории чата.

- **Request** (application/json)
  ```json
  {
    "text": "Текст запроса пользователя",
    "templateData": { "templateDescription": "Текст шаблона" },
    "manualRequest": false,
    "retryQuestion": false,
    "shotThinkingModel": false,
    "chatHistory": [
      { "role": "user",      "content": "Текст интервьюера или пользователя" },
      { "role": "assistant", "content": "Предыдущий ответ от ИИ" }
    ]
  }
  ```
  - `manualRequest` — автоматический или ручной запрос (А/Р или Р из интерфейса программы). Речь идет о режиме "Свободные руки". 
                    Когда система сама определяет, когда был задан вопрос и только в этом случае дает ответ (режим А/Р в интерфейсе программы).
                    На данный момент в адаптерах нет логики обработки автоматических запросов. Т.е. даже если текст не содержит вопроса, то ИИ попробует ответить что-нибудь. 
                    Если же вы хотите, чтобы если не было вопроса, то и не должно быть ответа (как реализовано на сервере Hintsage для режима А/Р), то вам следует
                    реализовать эту логику. И в случае, если вопрос не обнаружен, надо вернуть в качестве ответа строку NOQ. Тогда интерфейс ничего не покажет и продолжит работу.
                    В случае автоматического режима manualRequest будет иметь значение false, иначе true.
  - `retryQuestion` — повторный запрос на получение ответа (по правому клику мыши на сообщении).
  - `shotThinkingModel` — использовать «думающую» модель для шотов.
  - `chatHistory` — история сообщений (роль + текст).

- **Response**:
  - `text/event-stream` (ServerSent Events, поток токенов)
  - Каждый фрагмент — часть ответа.
  - Если вопроса нет — в потоке единственное сообщение:
    ```
    NOQ
    ```

---

### POST `/answer/shot/stream`

**Описание:** Генерирует ответ на основе текста и изображения (скриншота).

- **Request** (multipart/form-data)
  - `requestDto` — строка, в которой сериализован JSON как в `/answer/stream`.
  - `screenshot` — файл изображения.

- **Response**:
  - `text/event-stream` (SSE)
  - Поток токенов ответа (аналогично `/answer/stream`).

---

## Конфигурация

Все адаптеры читают параметры из `config.json` и/или переменных окружения:

- `API_BASE` — базовый URL API (например, `https://api.openai.com`).
- `API_KEY` — ключ доступа к сервису.
- `ANSWER_MODEL`, `SHOT_MODEL`, `THINKING_SHOT_MODEL` — имена моделей для конкретных ситуаций.
- `PROMPT`, `SHOT_PROMPT` — промпты для конкретных ситуаций.

---

## Пример запуска

```bash
# OpenAI адаптер
uvicorn openai_server:app --host 0.0.0.0 --port 8000 --no-use-colors

# OpenRouter адаптер
uvicorn openrouter_server:app --host 0.0.0.0 --port 8001 --no-use-colors
```

---

## Рекомендации

- Все адаптеры должны:
  - Принимать одинаковые DTO и возвращать поток SSE.
  - Возвращать `"NOQ"` при отсутствии вопроса.
  - Логировать ошибки и внешние вызовы.
- Новые адаптеры добавлять по аналогии: тот же интерфейс, тот же ответ.

---
