Адаптеры для сервиса помощи в прохождении собеседований https://hintsage.com

# LLM Адаптеры - директория llm

Здесь находятся адаптеры сервисов, предоставляющих LLM-модели для генерации текста на основе запроса.

- `openai_server.py` — адаптер для OpenAI сервера: https://openai.com/api/
- `openrouter_server.py` — адаптер для OpenRouter сервера: https://openrouter.ai/

---

## Интерфейс API

Каждый адаптер реализует два эндпоинта с одинаковыми структурами запросов и ответов.

### POST `/answer/stream`

**Описание:** Генерирует текстовый ответ на запрос пользователя с поддержкой истории чата.

- **Request** (application/json)
  ```json
  {
    "text": "Текст запроса пользователя",
    "templateData": { "templateDescription": "Текст шаблона" },
    "manualRequest": false,
    "retryQuestion": false,
    "shotThinkingModel": false,
    "chatHistory": [
      { "role": "user",      "content": "Текст интервьюера или пользователя" },
      { "role": "assistant", "content": "Предыдущий ответ от ИИ" }
    ]
  }
  ```
    - `manualRequest` — Сервис Hintsage поддерживат два режима работы.  
                      Ручной режим - это когда вы нажимаете кнопку "Получить ответ" и идет запрос на получение ответа от ИИ. В таком случае придет manualRequest = true.  
                      Автоматический режим - это когда система постоянно определяет, был ли задан вопрос и дает ответ, только если вопрос был обнаружен. 
                      В таком режиме пользователь не нажимает кнопку получения ответа. Вместо этого система постоянно обрабатывает новые данные диалога и сама определяет, когда давать ответ.  
                      В таком случае придет manualRequest = false. Здесь вам надо определять, есть ли в новых данных вопрос, на который надо дать ответ.  
                      В текущем кода адаптера автоматический режим не поддерживается. 
                      Но вы можете сами реализовать эту логику. Для этого вам надо определять, есть ли в пришедших данных вопрос, на который не был дан ответ. 
                      Если да - значит запросить ответ на него от ИИ, если нет - надо вернуть строку NOQ.
  - `retryQuestion` — повторный запрос на получение ответа (по правому клику мыши на сообщении).
  - `shotThinkingModel` — использовать «думающую» модель для шотов.
  - `chatHistory` — история сообщений (роль + текст).

- **Response**:
  - `text/event-stream` (ServerSent Events, поток токенов)
  - Каждый фрагмент — часть ответа.
  - Если вопроса нет — в потоке единственное сообщение:
    ```
    NOQ
    ```

---

### POST `/answer/shot/stream`

**Описание:** Генерирует ответ на основе текста и изображения (скриншота).

- **Request** (multipart/form-data)
  - `requestDto` — строка, в которой сериализован JSON как в `/answer/stream`.
  - `screenshot` — файл изображения.

- **Response**:
  - `text/event-stream` (SSE)
  - Поток токенов ответа (аналогично `/answer/stream`).

---

## Конфигурация

Все адаптеры читают параметры из `config.json` и/или переменных окружения:

- `API_BASE` — базовый URL API (например, `https://api.openai.com`).
- `API_KEY` — ключ доступа к сервису.
- `ANSWER_MODEL`, `SHOT_MODEL`, `THINKING_SHOT_MODEL` — имена моделей для конкретных ситуаций.
- `PROMPT`, `SHOT_PROMPT` — промпты для конкретных ситуаций.

---

## Пример запуска

```bash
# OpenAI адаптер
uvicorn openai_server:app --host 0.0.0.0 --port 8000 --no-use-colors

# OpenRouter адаптер
uvicorn openrouter_server:app --host 0.0.0.0 --port 8001 --no-use-colors
```

---

## Рекомендации

- Все адаптеры должны:
  - Принимать одинаковые DTO и возвращать поток SSE.
  - Логировать ошибки и внешние вызовы.
- Новые адаптеры добавлять по аналогии: тот же интерфейс, тот же ответ.

---
